{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/mkj9qwf17jbfrz94kdykryqh0000gn/T/ipykernel_48516/2752882984.py:10: DtypeWarning: Columns (5,6,49,52,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "#open csv\n",
    "filepath = os.path.join('..', 'Database', 'TBIMSPublic.2024-11-01', 'Data', 'Form2.csv')\n",
    "\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect\n",
    "df.info()\n",
    "print(df.notnull().sum())\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRTSchoolF', 'DeathCause2F', 'Rehosp1lv2F', 'Rehosp4lv2F', 'Rehosp5lv2F']\n",
      "DeathCause2F\n",
      "88888.0    58305\n",
      "99999.0     9120\n",
      "88888       4237\n",
      "99999       1228\n",
      "44444.0      513\n",
      "           ...  \n",
      "402.91         1\n",
      "701.0          1\n",
      "038.9          1\n",
      "429.2          1\n",
      "C34.90         1\n",
      "Name: count, Length: 411, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#inspect mixed columns index\n",
    "mixed_type_col = [15,6,49,52,53]\n",
    "\n",
    "#find column names\n",
    "mixed_type_col_names =[df.columns[column] for column in mixed_type_col]\n",
    "\n",
    "print(mixed_type_col_names)\n",
    "print(df['DeathCause2F'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      Mod2Id\n",
       "1                      Mod1Id\n",
       "2              FollowUpPeriod\n",
       "3                   IntStatus\n",
       "4                 LostReasonF\n",
       "                ...          \n",
       "307                   SRScalF\n",
       "308                 SWLSTOT4F\n",
       "309                  SWLSTOTF\n",
       "310    WordRecallCorrectF_i_n\n",
       "311       LastValidFollowupYN\n",
       "Name: Name, Length: 312, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_vars_filepath = os.path.join('..', 'Database', 'TBIMSPublic.2024-11-01', 'Code', 'Form2_Variables.csv')\n",
    "form_vars_df = pd.read_csv(form_vars_filepath)\n",
    "form_vars_df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_codes_filepath = os.path.join('..', 'Database', 'TBIMSPublic.2024-11-01', 'Code', 'Form2_Codes.csv')\n",
    "\n",
    "\n",
    "df_var_codes = pd.read_csv(var_codes_filepath)\n",
    "\n",
    "var_labels_dict ={}\n",
    "for var in df_var_codes['VariableName'].unique():\n",
    "    sub_df = df_var_codes[df_var_codes[\"VariableName\"] == var]\n",
    "    value_map = dict(zip(sub_df['Code'], sub_df['CodeDescription']))\n",
    "    var_labels_dict[var] = value_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    283\n",
       "int64       21\n",
       "object       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_code(code):\n",
    "    \"\"\" will convert to format 'string.0' \"\"\"\n",
    "    #try to convert to a float directly\n",
    "    try:\n",
    "        return str(float(code))\n",
    "    #if it can't be converted to a float, save it as a string\n",
    "    except ValueError:\n",
    "        return str(code)\n",
    "\n",
    "def process_mixed_variables(df, value_labels_dict, replace_col=False, code_col=False, code_label_col=False,errors=\"coerece\"):\n",
    "    \"\"\"\n",
    "    Cleans coded categorical/numeric variables using a value label dict.\n",
    "    Returns a cleaned dataframe and a summary.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    original_cols = df.columns\n",
    "    col_map = {col.lower(): col for col in original_cols}\n",
    "\n",
    "    new_columns = {}\n",
    "    summary_list = []\n",
    "\n",
    "\n",
    "    for var_raw, codes_dict in value_labels_dict.items():\n",
    "        var_lower = var_raw.lower()\n",
    "\n",
    "        if var_lower not in col_map:\n",
    "            continue\n",
    "\n",
    "        original_var = col_map[var_lower]\n",
    "\n",
    "        # Work on a lowercase temporary series for logic\n",
    "        temp_series = df[original_var].copy()\n",
    "\n",
    "        # Normalize for mapping\n",
    "        code_keys = set(normalize_code(k) for k in codes_dict.keys())\n",
    "\n",
    "        # Convert entries for numeric masking\n",
    "        temp_series = temp_series.apply(lambda x: str(float(x)) if pd.notna(x) and str(x).replace('.', '', 1).isdigit() else x)\n",
    "        clean_series = pd.to_numeric(temp_series.mask(temp_series.isin(code_keys)), errors=errors)\n",
    "\n",
    "        mapped_dict = {str(float(k)) if k.isdigit() else k: v for k, v in codes_dict.items()}\n",
    "        label_series = temp_series.map(mapped_dict)\n",
    "\n",
    "        # Output columns using original name\n",
    "        if replace_col:\n",
    "            new_columns[original_var] = clean_series\n",
    "        else:\n",
    "            new_columns[f'{original_var}_clean'] = clean_series\n",
    "\n",
    "        if code_col:\n",
    "            new_columns[f'{original_var}_code'] = temp_series.where(temp_series.isin(code_keys))\n",
    "        \n",
    "        if code_label_col:\n",
    "            new_columns[f'{original_var}_code_label'] = label_series\n",
    "\n",
    "        summary = {\n",
    "            \"Variable\": original_var,\n",
    "            \"Valid Count\": clean_series.count(),\n",
    "            \"Mean\": clean_series.mean(),\n",
    "            \"Std Dev\": clean_series.std(),\n",
    "            \"all_categorical\": clean_series.isna().all()\n",
    "        }\n",
    "\n",
    "        summary.update(label_series.value_counts().to_dict())\n",
    "        summary_list.append(summary)\n",
    "    \n",
    "\n",
    "    # Drop old versions of columns being replaced\n",
    "    df = df.drop(columns=new_columns.keys(), errors='ignore')\n",
    "    df = pd.concat([df, pd.DataFrame(new_columns)], axis=1)\n",
    "    summary_df = pd.DataFrame(summary_list).infer_objects(copy=False)\n",
    "\n",
    "    return df, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mod2Id', 'Mod1Id', 'FollowUpPeriod', 'DeathCause1F', 'DeathCause2F', 'DeathECodeF', 'Rehosp1lv2F', 'Rehosp2lv2F', 'Rehosp3lv2F', 'Rehosp4lv2F', 'Rehosp5lv2F', 'HeightF', 'WeightF', 'ALCWeekF', 'ALCDrinksF', 'ALC5DrinksF', 'ALC4DrinksF', 'drs3_1F', 'WordRecallPrimacyF', 'WordRecallMiddleF', 'WordRecallRecencyF', 'WordRecallCorrectF', 'WordRecallRepF', 'WordRecallIntF', 'BackDigitCorrectF', 'FluencyCorrect1_15F', 'FluencyCorrect15_30F', 'FluencyCorrect30_45F', 'FluencyCorrect45_60F', 'FluencyCorrectF', 'FluencyRepF', 'FluencyIntF', 'ReasonCorrectF', 'BackCountLastNumF', 'BackCountErrorsF', 'BackCountDigitsF', 'BackCountTimeF', 'DelayWordRecallPrimacyF', 'DelayWordRecallMiddleF', 'DelayWordRecallRecencyF', 'DelayWordRecallCorrectF', 'DelayWordRecallRepF', 'DelayWordRecallIntF', 'LengthInterviewF', 'DRSEmpF', 'DRSFeedF', 'DRSToiletF', 'DRSGroomF', 'DRSFuncF', 'SchoolF', 'ALCMonthF', 'AGENoPHIF', 'B3TCOMPF', 'B3TEFF', 'B3TEMF', 'BackCountDigitsF_i_n', 'BackDigitCorrectF_i_n', 'BMIF', 'CombinedDRSF', 'CombinedDRSTypeF', 'DAYSTo1stEmpF', 'DAYStoDEATHF', 'DAYStoFUF', 'DelayWordRecallCorrectF_i_n', 'DRS_PI_ORIGF', 'DRS_PIEmpF', 'DRS_PIF', 'DRS_PIFeedF', 'DRSF', 'DRSHighF', 'DRSLowF', 'EDUCATIONF', 'FIMCOGF', 'FIMMOTF', 'FIMTOTF', 'FluencyCorrectF_i_n', 'FUYearF', 'GAD7TOTF', 'Malec_EatOutF', 'Malec_FriendF', 'Malec_MovieF', 'Malec_OutHseF', 'Malec_PlaySportF', 'Malec_ProdF', 'Malec_RelationF', 'Malec_ReligionF', 'Malec_ShopF', 'Malec_SocialF', 'Malec_SumF', 'Malec_WatchSportF', 'PART_BalancedF', 'PART_Domain_OutF', 'PART_Domain_ProdF', 'PART_Domain_SocF', 'PART_RaschF', 'PART_SDF', 'PARTOutAboutF', 'PARTProductivityF', 'PARTSocialF', 'PARTSummaryF', 'PHQ9TOTF', 'PROBLEMUseF', 'ReasonCorrectF_i_n', 'SRScal2F', 'SWLSTOT4F', 'SWLSTOTF', 'WordRecallCorrectF_i_n', 'LastValidFollowupYN']\n"
     ]
    }
   ],
   "source": [
    "df_decoded, summary = process_mixed_variables(df, var_labels_dict, replace_col=True,code_col=True,code_label_col=True,errors=\"coerce\")\n",
    "\n",
    "col_map = {col.lower(): col for col in df.columns} \n",
    "\n",
    "categorical_cols = summary[summary['all_categorical'] == True]['Variable'].str.lower().str.strip().tolist()\n",
    "\n",
    "continuous_cols = [\n",
    "    i.lower().strip()\n",
    "    for i in form_vars_df['Name'].unique()\n",
    "    if i.lower().strip() not in categorical_cols\n",
    "]\n",
    "\n",
    "continuous_cols = list(map(col_map.get, continuous_cols))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'PI_Original'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_decoded[continuous_cols].astype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/generic.py:6643\u001b[39m, in \u001b[36mastype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mastype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mapply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[39m, in \u001b[36mastype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'PI_Original'"
     ]
    }
   ],
   "source": [
    "df_decoded[continuous_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Compute IQR\u001b[39;00m\n\u001b[32m      3\u001b[39m data = df_decoded[continuous_cols]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m Q1 = data.quantile(\u001b[32m0.25\u001b[39m)\n\u001b[32m      7\u001b[39m Q3 = data.quantile(\u001b[32m0.75\u001b[39m)\n\u001b[32m      8\u001b[39m IQR = Q3 - Q1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/frame.py:12146\u001b[39m, in \u001b[36mquantile\u001b[39m\u001b[34m(self, q, axis, numeric_only, interpolation, method)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/frame.py:12191\u001b[39m, in \u001b[36mquantile\u001b[39m\u001b[34m(self, q, axis, numeric_only, interpolation, method)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:1548\u001b[39m, in \u001b[36mquantile\u001b[39m\u001b[34m(self, qs, interpolation)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:1549\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1891\u001b[39m, in \u001b[36mquantile\u001b[39m\u001b[34m(self, qs, interpolation)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/array_algos/quantile.py:39\u001b[39m, in \u001b[36mquantile_compat\u001b[39m\u001b[34m(values, qs, interpolation)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/array_algos/quantile.py:97\u001b[39m, in \u001b[36mquantile_with_mask\u001b[39m\u001b[34m(values, mask, fill_value, qs, interpolation)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/pandas/core/array_algos/quantile.py:218\u001b[39m, in \u001b[36m_nanpercentile\u001b[39m\u001b[34m(values, qs, na_value, mask, interpolation)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4273\u001b[39m, in \u001b[36mpercentile\u001b[39m\u001b[34m(a, q, axis, out, overwrite_input, method, keepdims, weights, interpolation)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4550\u001b[39m, in \u001b[36m_quantile_unchecked\u001b[39m\u001b[34m(a, q, axis, out, overwrite_input, method, keepdims, weights)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:3894\u001b[39m, in \u001b[36m_ureduce\u001b[39m\u001b[34m(a, func, keepdims, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4727\u001b[39m, in \u001b[36m_quantile_ureduce_func\u001b[39m\u001b[34m(a, q, weights, axis, out, overwrite_input, method)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4859\u001b[39m, in \u001b[36m_quantile\u001b[39m\u001b[34m(arr, quantiles, axis, method, out, weights)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/PREDDICT-SPAULDING/.conda/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4653\u001b[39m, in \u001b[36m_lerp\u001b[39m\u001b[34m(a, b, t, out)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "#Compute IQR\n",
    "\n",
    "data = df_decoded[continuous_cols]\n",
    "\n",
    "\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds (you can adjust the multiplier)\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "\n",
    "ax = filtered_data.hist(figsize=(20, 17))\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.6, wspace=0.7)\n",
    "plt.title(\"Histogram (Outliers Removed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
